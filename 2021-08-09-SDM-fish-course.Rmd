---
title: "Data wrangling and GIS for species distribution models in R"
author: "CJ Brown"
date: "20 Sept 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

TODO: write the course
edit model predictions part 


# Introduction 

R is the leading programming language for ecological modelling for good reason. Being free and open-source certainly helps. Having strengths in dataviz also helps. But because of these traits, R now has a huge ecosystem of user-contributed packages that enable sophisticated modelling applications. 

This ecosystem is created by a huge community of R users, many of whom are leaders in their field developing cutting edge statistical models and data science tools. This means if you know R, you can access cutting edge tools and combine them in new ways. 

While there are other languages that excel for scientific computing, R owns the market in species distribution modelling (SDMs), the topic of this course. 

Until quite recently most R users would prepare their data outside of R (e.g. in Arc GIS) and then read it into R for the SDM. But R now also has efficient and user friendly GIS and mapping packages. This means you can create your entire SDM workflow, from data download to visualization, in R. 

But starting an SDM project in R can be daunting for new users. There is a steep learning curve for coding, and there are so many options for packages it is easy to get decision paralysis. 

So in this course we are going to provide an introduction to some common SDMs in R. We will also learn how to build an efficient workflow. Our goals today are:

1. Overview R's capability for GIS and spatial dataviz  

2. Learn how to build efficient and repeatable workflows for SDMs  

3. Learn how to run some SDMs  

4. Learn how to visualize spatial data and SDM results   

# Methods we will cover

TODO
GAMs
spatial AC...

## What you'll need 

TODO

Packages

```{r, eval=FALSE}
install.packages(c("tmap", "tidyverse", "terra",
                   "sf", "nlme", 
                   "patchwork", "visreg"))

```


New packages: patchwork, visreg


## Case-study: Bumphead parrotfish in Solomon Islands

TODO

[](https://github.com/cbrown5/BenthicLatent)

## Planning your project 

An important part of R coding is having an organized workflow. Being organized is important in anything more complex than a one-step R program, which will be most projects involving SDMs. Organizing your workflow requires forward planning and sticking to some strategies. In this course we'll follow a simple workflow. 

There are multiuple benefits of an organized workflow. You code will be more transparent and repeatable, this will benefit both future you and other researchers. It also means you are less likely to make mistakes and the code is easier to debug when you do. Finally, you may want to share the code publicly so other people can repeat your work. 

First, you'll want to identify your research question. If your question is clear then you can stick to what you need to do, and not end up going down rabbit holes creating code you won't use. Once you have that question I recommmend considering fives steps in your workflow: 

### 1. Gather the data 

You will need to source data, often from online data repositories. Even if you have collected species observations yourself, you will likely need to get environmental covariates for prediction from sources such as weather bureaus, oceanographic repositories or climate models. 

### 2. Data wrangling 

The data needs to be read into R and 'wrangled' into the appropriate data structure for the modelling packages you will use. Just a warning, some packages require different data structures, so make sure you know what you want! For a spatial model this step can involve a lot of (complex) GIS. Thankfully, R has good packages for GIS. 

### 3. Dataviz 

Before starting I always use R's powerful data visualisation tools to explore the data. This gives you a deeper understanding of what you'll model, can help avoid conceptual flaws. Also, you may want to save some data plots for your publication. In this course we'll use R markdown to make a report on our data that can be easily shared with collaborators. 

### 4. Modelling  

Finally, we get to the modelling. This is where we'll spend most time in this course 


### 5. Modelviz  

A powerful way to communicate your models is by making more dataviz. In this course we'll use dataviz look at what the models say are important environmental drivers of fish abundance, and see how we can use the model to make predictions to unsampled sites. 

One final note, the above can be an iterative process. But organize your R scripts like the above and it will be much easier. 




### 1. Gather the data 

You should have the data for this course already, if not [download it from github](TODO)

Online Repos.... 
rnaturalearth, satellite products.... 


#### Simple dataframes 

```{r}
library(readr)
library(ggplot2)
library(dplyr)
dat <- read_csv("data/JuvUVCSites_with_ReefTypes_16Jun2016.csv")
names(dat)
```  

There are coordinates, but because this is a dataframe there is no CRS! Something to make sure you ask data providers (or provide the files as spatial files). 

```{r}
ggplot(dat) + 
  aes(x = secchi, y = pres.topa) + 
  geom_point() + 
  stat_smooth()

ggplot(dat) + 
  aes(x = logged, y = pres.topa) + 
  geom_boxplot()
```

```{r}
theme_set(theme_classic())
```


```{r}
bendat <- read_csv("data/BenthicCoverSurveys.csv")
head(bendat)
ggplot(bendat) + 
  aes(x = category,y = cover) + 
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 90))
```

#### Spatial data 

```{r}
library(sf)
logponds <- st_read("data/Kia_Logging_Ponds/Kia_Logging_Ponds.shp")
plot(logponds[1])
```

```{r}
land <- st_read("data/LandPoly/LandPoly.shp")
plot(land[1])
```


### 2. Data wrangling 

#### Summarizing benthic cover data 
```{r}
CB_dat <- filter(bendat, code == "ACB")
CB_dat <- filter(bendat, code %in% c("ACB", "CB"))
CB_dat <- group_by(CB_dat, site)
CB_dat <- summarize(CB_dat, CB_cover = sum(cover),
                    n_pts = mean(n_pts))
```
This whole thing could be more straightforward with pipes:

```{r}
soft_dat <- bendat %>%
  filter(code %in% c("S", "SI")) %>% #Sand or Silt
  group_by(site) %>% 
  summarize(soft_cover = sum(cover),
                    n_pts = mean(n_pts))
```

```{r}
nrow(dat)
dat2 <- left_join(dat, CB_dat, by = "site")
nrow(dat2)
dat2 <- left_join(dat2, soft_dat, by = c("site", "n_pts"))
nrow(dat2)
``` 

```{r}
ggplot(dat2) + 
  aes(x = logged, y = CB_cover) + 
  geom_boxplot()
```
```{r}
ggplot(dat2) + 
  aes(x = CB_cover, y = pres.topa) + 
  geom_point()

```


```{r}
ggplot(dat2) + 
  aes(x = CB_cover, y = soft_cover) + 
  geom_point()

```



```{r eval=FALSE}
icol <- sapply(dat2, is.numeric)
pairs(dat2[,icol])
round(cor(dat2[,icol]),2)
```

#### Creating spatial points files 

```{r}
kia_crs <- st_crs(logponds)
sdat2 <- st_as_sf(dat2, coords = c("coordx", "coordy"),
                  crs = kia_crs)
plot(sdat2["pres.topa"])
```

#### Spatial data wrangling: transforming CRS

```{r}
st_crs(land) == kia_crs

```
```{r}
land <- st_transform(land, kia_crs)
st_crs(land) == kia_crs
```  

#### Spatial data wrangling: distances 

```{r}
distmat <- st_distance(sdat2, logponds)
dim(distmat)
```

```{r}
apply(distmat, 1, min)[1:5]

```

```{r}
sdat2$dist_to_logging <- apply(distmat, 1, min)/1000
ggplot(sdat2) + 
  aes(x = dist_to_logging, y = pres.topa) + 
  geom_point()
```



### 3. Dataviz 

```{r}
library(patchwork)
```



```{r}
g1 <- ggplot(sdat2) + 
  aes(x = dist_to_logging, y = secchi) + 
  geom_point() + 
  stat_smooth()
g1
```
```{r}
g2 <- ggplot(sdat2) + 
  aes(x = dist_to_logging, y = CB_cover) + 
  geom_point() +
  stat_smooth()

g3 <- ggplot(sdat2) + 
  aes(x = CB_cover, y = pres.topa) + 
  geom_point() + 
    stat_smooth()

```

```{r}
gall <- g1 + g2 + g3
gall
``` 

```{r eval=FALSE}
ggsave("plot1.png", gall, width = 8, height = 3)
```


```{r}
library(tmap)
```

```{r}
tm_shape(sdat2) + 
  tm_symbols(col = "pres.topa", size = 0.2)
```
```{r}
tland <- tm_shape(land) + 
  tm_fill()
tland + 
  tm_shape(sdat2) + 
  tm_symbols(col = "pres.topa", size = 0.2) +
  tm_scale_bar(position = c("right", "top"))
```



### 4. Modelling  

Preparation 

Use distance, not CB cover 

Going to start with simpler models and work our way through. In a real workflow you might do things differently. 

Focus on model based approaches. Other alteranatives are machine learning, BRTs, maxent, random forest etc... 
Do so b/c of spatial AC

```{r}
sdat2$log10_dist_logging <- log10(sdat2$dist_to_logging)
```


#### Generalized linear model 

```{r}
library(visreg)
```

```{r}
glm1_gaus <- glm(pres.topa ~ log10_dist_logging + flow, data = sdat2)
par(mfrow = c(2,2))
plot(glm1_gaus)
```

```{r}
glm1_pois <- glm(pres.topa ~ log10_dist_logging + flow, data = sdat2,
          family = "poisson")
par(mfrow = c(2,2))
plot(glm1_pois)
```
```{r}
library(MASS)
glm1_nb <- glm.nb(pres.topa ~ log10_dist_logging + flow, data = sdat2)
par(mfrow = c(2,2))
plot(glm1_nb)
```

```{r}
AIC(glm1_gaus, glm1_pois, glm1_nb)
```

```{r}
summary(glm1_nb)
```


#### Spatial autocorrelation  

```{r}
sdat2$resid_glm_pois <- resid(glm1_pois)

tm_shape(land) + 
  tm_polygons() + 
  tm_shape(sdat2) + 
  tm_symbols(col = "resid_glm_pois", size = 0.5)
```
```{r}
source("data/semivariance.R")
site_distmat <- st_distance(sdat2)/1000
dim(site_distmat)
glm1_pois_semivar <- semivariance(site_distmat, sdat2$resid_glm_pois, ncats = 15)

ggplot(glm1_pois_semivar) + 
  aes(x = distances, y = semivar) + 
  geom_point() + 
  stat_smooth()

```

```{r}
glm_nb_plots <- plot_spatial_AC(sdat2, glm1_nb, site_distmat)
tland + glm_nb_plots[[1]]
glm_nb_plots[[2]]
```


#### Generalized least squares

```{r}
library(nlme)
sdat2$sqrt_topa <- sqrt(sdat2$pres.topa)

m1_gls <- gls(sqrt_topa ~ log10_dist_logging + flow, 
              data = sdat2)

```

```{r}
sdat2$x <- st_coordinates(sdat2)[,1]
sdat2$y <- st_coordinates(sdat2)[,2]
cs1Sph <- corSpher(1, form = ~x + y)

m2_gls <- gls(sqrt_topa ~ log10_dist_logging + flow, 
              data = sdat2,
              correlation = cs1Sph)

plot(m2_gls)
```

```{r}
summary(m2_gls)
```


```{r}
gls_plots <- plot_spatial_AC(sdat2, m2_gls, site_distmat)
gls_plots[[2]]
```



#### Generalized additive model 

```{r}
library(mgcv)
m1_gam <- gam(pres.topa ~ s(log10_dist_logging) + flow,
              family = "nb",
              data = sdat2)
visreg(m1_gam)
```

Compare this to the model where distance isn't logged!

```{r}
m1_gam_plots <- plot_spatial_AC(sdat2, m1_gam, site_distmat)

tland + m1_gam_plots[[1]]
m1_gam_plots[[2]]

```

#### Generalized additive model with spatial covariates

```{r}
m2_gam <- gam(pres.topa ~ s(x, y, bs = "gp"),
              family = "nb",
              data = sdat2)
plot(m2_gam, se = FALSE)
```

```{r}
m2_gam_plots <- plot_spatial_AC(sdat2, m2_gam, site_distmat)

tland + m2_gam_plots[[1]]
m2_gam_plots[[2]]

```
```{r}
m3_gam <- gam(pres.topa ~ s(log10_dist_logging) + 
                s(x, y, bs = "gp"),
              family = "poisson",
              data = sdat2)
plot(m3_gam)

```

No spatial AC 

```{r}

```


### 5. Modelviz  

#### Plotting predictions

m1_gam
m2_gam

```{r}
g1 <- visreg(m1_gam, xvar = "log10_dist_logging",
       scale = "response", gg = TRUE) + 
  xlab("Distance to log ponds (log10)") + 
  ylab("Topa abundance")
g1
```
Mean plus 95% CIs. 


```{r}
flow_pred <- visreg(m1_gam, xvar = "flow",
       scale = "response", gg = TRUE, plot = FALSE)

g2 <- ggplot(flow_pred$fit) + 
  aes(x = flow, y = visregFit) + 
  geom_point() + 
  geom_linerange(aes(ymin = visregLwr, ymax = visregUpr)) + 
  xlab("Flow") + 
  ylab("Topa abundance")

gboth <- g1 + g2 + 
  plot_layout(nrow = 1, widths = c(1, 0.5)) + 
  plot_annotation(tag_levels = "A")

gboth
```

```{r eval=FALSE}
ggsave("m1_gam_predictions.png", plot = gboth,
       width = 6, 
       height = 3)

```

#### Spatial predictions 


## Generating and mapping model predictions 

If we want to map our predictions for fish abundance, we will need to use rasters. 

### Generating predictions at the sample locations

If we wanted to generate predictions at the original sample sites, we could just say: 

```{r}
sdat2$gam1_pred <- predict(m1_gam, type = "response")
```

And then plot the predictions with tmap:

```{r}
tland + 
  tm_shape(sdat2) +
  tm_symbols(col = "gam1_pred", size = 0.3) 
```

This looks ok, but we might like to extent the edges of the points a bit to fill out the map a bit more. There are a few ways to do this, we will use rasters. 

#### Generating predictions anywhere 


Now we do some tricker to get predictions for the raster grid. 

We need to set up a dataframe that has the SST values and x values (longitudes) from the raster and their cell numbers. Cells are numbered 1 to the total number of cells, starting at the top left cell. 

I've given two options below for choosing cells. The first is more conservative and just chooses cells that have samples (we commented it out). The second uses all ocean cells (we'll do this one now): 


```{r}
library(terra)
```



```{r}
land_terra <- vect(land)
plot(land_terra)

kia_crs_terra <- crs(land_terra)
```


```{r}
rlogponds <- rast(extent = ext(land_terra), crs = crs(land_terra),
     res  = 500)

xy <- st_coordinates(logponds)
icell <- cellFromXY(rdist, xy)
rlogponds[icell] <- 1

tland + 
tm_shape(rlogponds) + 
  tm_raster(palette = "Dark2")
```

```{r}
rdist <- distance(rlogponds)
rdist_log10 <- rast(rdist)
rdist_log10[] <- log10(rdist[]/1000)
tm_shape(rdist_log10) + 
  tm_raster(palette = "-YlOrBr", n = 7) + 
  tland 

```



```{r}
icell <- 1:ncell(rdist_log10)
pred <- data.frame(log10_dist_logging = rdist_log10[icell][,1],
                       cells = icell, 
                       x = xFromCell(rdist_log10, icell),
                      y = yFromCell(rdist_log10, icell), 
                   flow = "Mild") 

pred <- filter(pred, is.finite(log10_dist_logging))
head(pred)
```

We used `na.omit` to get rid of `NA` SST values (land basically). 

Now we can use `predict` to predict the richness values for `m_int`, but with our new SST and x values, using the `newdata` argument. 

```{r}
pred$topa_pred <- predict(m1_gam, newdata = pred, type = "response")
``` 

We chose the `response` type, so that predictions units of species richness, not log species richness (because of the log link in the negative binomial).

Now we just assign the predictions back to an empty raster. The empty raster is just a copy of `rsst` with no data. 

```{r}
rpred <- rast(rdist_log10)
rpred[pred$cells] <- matrix(pred$topa_pred, ncol = 1)
```

We specify `rpred[pred$cells]` so it only adds in values in the cells we predited too. 

Finally use your tmap skills to make a map Prof Calanoid will love: 

```{r}
tm_shape(rpred) + 
  tm_raster(palette = "Blues",
            title= "Predicted abundance", alpha = 0.8, n=10) + 
  tm_shape(land) +
  tm_fill(col = "black") +
  tm_shape(logponds) + 
  tm_symbols(col = "brown", size = 0.3) + 
  tm_layout(bg.color = "grey20", 
            legend.position = c("LEFT", "bottom"),
            legend.text.color = "white", 
            legend.title.color = "white")
```

It looks blocky, that's because we predicted richness to the underlying raster. Arguably the 'blockiness' is actually good in this case - these are model predictions, not real data, the blockiness serves to emphasise that. 

Have a go at doing a map for m2_gam




# Resources 

tmap


https://rspatial.org/raster/sdm/index.html

clone repo so I can get spatial data


- look at confounding of variables

#### Bonus content: intersecting spatial layers

```{r}
reefs <- st_read("data/Kia reefs/Reef_Strata_Kia.shp")
names(reefs)
st_crs(reefs) == kia_crs
reefs <- st_transform(reefs, kia_crs)
```


```{r eval = FALSE}
sdat3 <- st_intersection(sdat2, reefs)
```
`Error in CPL_geos_op2(op, x, y) : Evaluation error: TopologyException: Input geom 1 is invalid: Ring Self-intersection at or near point 439615.50008775701 9152047.0008130241 at 439615.50008775701 9152047.0008130241.`  


```{r}
reefs2 <- st_buffer(reefs, dist =0.0)
sdat3 <- st_intersection(sdat2, reefs2)
plot(sdat3["L3_ATTRIB"])
```

But many sites are missing. TODO buffer...

Making a raster of land from polygons with rasterize
```{r}
rland <- rast(extent = ext(land_terra), crs = crs(land_terra),
     res  = 100)
rland <- rasterize(land_terra, rland)
```

